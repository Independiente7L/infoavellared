import pandas as pd
from datetime import datetime
import re
import time
from urllib.parse import unquote
import logging
import os
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class FootballScraperSelenium:
    def __init__(self):
        self.results = []
        self.driver = None
        self.successful_extractions = 0
        self.excel_filename = "proximos_partidos.xlsx"
        
        # Mapeo de URLs a equipos espec√≠ficos
        self.team_mapping = {
            'arsenal': 'Arsenal FC',
            'union+magdalena': 'AD Union Magdalena',
            'gimnasia+mendoza': 'CA Gimnasia y Esgrima (Mendoza)',
            'puebla': 'Club Puebla',
            'tigre': 'CA Tigre',
            'chacarita': 'CA Chacarita Juniors',
            'los+andes': 'CA Los Andes',
            'volos': 'Volos NPS',
            'boston+river': 'CA Boston River',
            'maldonado': 'Club Deportivo Maldonado',
            'circulo+deportivo': 'C√≠rculo Deportivo',
            'platense': 'CA Platense',
            'nueva+chicago': 'CA Nueva Chicago',
            'real+pilar': 'Real Pilar FC',
            'tristan+suarez': 'CSD Trist√°n Su√°rez',
            'barracas+central': 'CA Barracas Central',
            'barcelona+guayaquil': 'Barcelona SC Guayaquil',
            'dock+sud': 'CS Dock Sud',
            'atletico+tucuman': 'Club Atl√©tico Tucum√°n',
            'liverpool+montevideo': 'Liverpool FC Montevideo',
            'rosario+central': 'CA Rosario Central',
            'san+martin+san+juan': 'CA San Mart√≠n (San Juan)'
        }
    
    def setup_selenium(self):
        """Configura Selenium WebDriver"""
        try:
            logging.info("üîß Configurando Selenium WebDriver...")
            chrome_options = Options()
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.wait = WebDriverWait(self.driver, 15)
            logging.info("‚úÖ Selenium configurado correctamente")
        except Exception as e:
            logging.error(f"‚ùå Error configurando Selenium: {e}")
            raise
    
    def extract_team_from_url(self, url):
        """Extrae el nombre del equipo de la URL de b√∫squeda usando el mapeo espec√≠fico"""
        try:
            decoded_url = unquote(url).lower()
            
            # Buscar en el mapeo espec√≠fico
            for key, team_name in self.team_mapping.items():
                if key in decoded_url:
                    return team_name
            
            # Fallback: extraer de la URL como antes
            match = re.search(r'[?&]q=([^&]+)', decoded_url)
            if match:
                query = match.group(1).replace('+', ' ')
                team_name = re.sub(r'\s*(proximo|pr√≥ximo)\s*partido\s*', '', query, flags=re.IGNORECASE).strip()
                return team_name.title()
                
        except Exception as e:
            logging.error(f"Error extrayendo equipo de URL: {e}")
        return "Equipo no identificado"
    
    def determine_rival(self, team_searched, equipo_local, equipo_visitante):
        """Determina cu√°l es el rival del equipo que se busca"""
        try:
            # Normalizar nombres para comparaci√≥n
            team_searched_norm = team_searched.lower()
            local_norm = equipo_local.lower()
            visitante_norm = equipo_visitante.lower()
            
            # Buscar coincidencias parciales con el equipo buscado
            if any(word in local_norm for word in team_searched_norm.split() if len(word) > 3):
                return equipo_visitante
            elif any(word in visitante_norm for word in team_searched_norm.split() if len(word) > 3):
                return equipo_local
            else:
                # Si no hay coincidencia clara, intentar con palabras clave del equipo
                team_keywords = team_searched_norm.replace('ca ', '').replace('fc ', '').replace('club ', '').split()
                
                for keyword in team_keywords:
                    if len(keyword) > 3:
                        if keyword in local_norm:
                            return equipo_visitante
                        elif keyword in visitante_norm:
                            return equipo_local
                
                # Si a√∫n no hay coincidencia, retornar info del partido
                return f"vs {equipo_visitante}" if equipo_local != 'No encontrado' else 'No identificado'
                
        except Exception as e:
            logging.error(f"Error determinando rival: {e}")
            return 'Error determinando rival'
    
    def scrape_match_info(self, url):
        """Extrae informaci√≥n del partido usando Selenium"""
        try:
            if self.driver is None:
                self.setup_selenium()
            
            team_searched = self.extract_team_from_url(url)
            logging.info(f"üåê Procesando con Selenium: {team_searched}")
            
            self.driver.get(url)
            time.sleep(5)  # Esperar a que cargue la p√°gina
            
            match_info = {
                'Club Actual': team_searched,
                'equipo_local': 'No encontrado',
                'equipo_visitante': 'No encontrado',
                'Pr√≥ximo Partido': 'No encontrada',
                'competicion': 'No encontrada',
                'fase_jornada': 'No encontrada',
                'jornada_numero': 'No encontrada',
                'estado': 'Pr√≥ximo',
                'Pr√≥ximo Rival': 'No identificado'
            }
            
            # Buscar equipos
            team_selectors = [
                "div.imso_mh__tm-nm span[aria-hidden='true']",
                "span[aria-hidden='true']",
                "div.ellipsisize span[aria-hidden='true']"
            ]
            
            teams_found = []
            for selector in team_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        text = elem.text.strip()
                        if text and len(text) > 1 and text not in teams_found:
                            teams_found.append(text)
                    if len(teams_found) >= 2:
                        break
                except Exception:
                    continue
            
            if len(teams_found) >= 2:
                match_info['equipo_local'] = teams_found[0]
                match_info['equipo_visitante'] = teams_found[1]
                
                # Determinar el rival
                match_info['Pr√≥ximo Rival'] = self.determine_rival(
                    team_searched, 
                    match_info['equipo_local'], 
                    match_info['equipo_visitante']
                )
            
            # Buscar competici√≥n
            comp_selectors = [
                "span.imso-ln",
                "span[jscontroller='zhya9d']",
                "span[style*='color:#E9C018']"
            ]
            
            for selector in comp_selectors:
                try:
                    elem = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if elem.text.strip():
                        match_info['competicion'] = elem.text.strip()
                        break
                except Exception:
                    continue
            
            # Buscar fecha y hora
            datetime_selectors = [
                "span.imso_mh__lr-dt-ds",
                "span[class*='dt-ds']"
            ]
            
            for selector in datetime_selectors:
                try:
                    elem = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if elem.text.strip():
                        match_info['Pr√≥ximo Partido'] = elem.text.strip()
                        break
                except Exception:
                    continue
            
            # Buscar fase y jornada
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, "div.imso_mh_s__lg-st-srs div")
                for elem in elements:
                    text = elem.text.strip()
                    if text and ('jornada' in text.lower() or 'fase' in text.lower()):
                        match_info['fase_jornada'] = text
                        jornada_match = re.search(r'jornada\s*(\d+)', text, re.IGNORECASE)
                        if jornada_match:
                            match_info['jornada_numero'] = jornada_match.group(1)
                        break
            except Exception:
                pass
            
            # Verificar si encontramos informaci√≥n √∫til
            useful_data = (
                match_info['equipo_local'] != 'No encontrado' or 
                match_info['competicion'] != 'No encontrada' or 
                match_info['Pr√≥ximo Partido'] != 'No encontrada'
            )
            
            if useful_data:
                logging.info(f"‚úÖ Extracci√≥n exitosa para {team_searched}")
                self.successful_extractions += 1
            else:
                logging.warning(f"‚ö†Ô∏è No se encontraron datos √∫tiles para {team_searched}")
                match_info['estado'] = 'Sin datos'
                
            return match_info
                
        except Exception as e:
            logging.error(f"‚ùå Error procesando {url}: {str(e)}")
            team_searched = self.extract_team_from_url(url)
            return {
                'equipo_buscado': team_searched,
                'equipo_local': 'Error en extracci√≥n',
                'equipo_visitante': 'Error en extracci√≥n',
                'Pr√≥ximo Partido': 'Error',
                'competicion': 'Error',
                'fase_jornada': 'Error',
                'jornada_numero': 'Error',
                'estado': 'Error',
                'Pr√≥ximo Rival': 'Error'
            }
    
    def scrape_multiple_urls(self, urls):
        """Procesa m√∫ltiples URLs"""
        logging.info(f"üöÄ Iniciando scraping de {len(urls)} URLs con Selenium")
        
        for i, url in enumerate(urls, 1):
            logging.info(f"\nüìä Procesando URL {i}/{len(urls)}")
            logging.info(f"üîó {url[:100]}...")
            
            match_info = self.scrape_match_info(url)
            self.results.append(match_info)
            
            # Pausa entre requests para evitar bloqueos
            if i < len(urls):
                time.sleep(3)
        
        return self.results
    
    def update_excel(self):
        """Actualiza el archivo Excel existente o crea uno nuevo"""
        try:
            df_new = pd.DataFrame(self.results)
            
            # Reordenar columnas seg√∫n especificaciones
            column_order = [
                'equipo_buscado', 'Pr√≥ximo Rival', 'Pr√≥ximo Partido',
                'equipo_local', 'equipo_visitante', 'competicion', 
                'fase_jornada', 'jornada_numero', 'estado'
            ]
            df_new = df_new[column_order]
            
            # Verificar si el archivo existe
            if os.path.exists(self.excel_filename):
                logging.info(f"üìù Actualizando archivo existente: {self.excel_filename}")
                
                # Leer el archivo existente
                try:
                    df_existing = pd.read_excel(self.excel_filename, sheet_name='Sheet1')
                    
                    # Actualizar los datos existentes o agregar nuevos
                    for _, new_row in df_new.iterrows():
                        equipo = new_row['equipo_buscado']
                        
                        # Buscar si el equipo ya existe
                        if equipo in df_existing['equipo_buscado'].values:
                            # Actualizar la fila existente
                            idx = df_existing[df_existing['equipo_buscado'] == equipo].index[0]
                            for col in df_new.columns:
                                df_existing.loc[idx, col] = new_row[col]
                            logging.info(f"üîÑ Actualizado: {equipo}")
                        else:
                            # Agregar nueva fila
                            df_existing = pd.concat([df_existing, new_row.to_frame().T], ignore_index=True)
                            logging.info(f"‚ûï Agregado: {equipo}")
                    
                    df_final = df_existing
                    
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Error leyendo archivo existente: {e}")
                    logging.info("üìù Creando archivo nuevo con los datos actuales")
                    df_final = df_new
            else:
                logging.info(f"üìù Creando nuevo archivo: {self.excel_filename}")
                df_final = df_new
            
            # Crear hoja de estad√≠sticas
            stats_data = {
                'M√©trica': [
                    'Total equipos procesados',
                    'Extracciones exitosas',
                    'Tasa de √©xito (%)',
                    'M√©todo utilizado',
                    '√öltima actualizaci√≥n'
                ],
                'Valor': [
                    len(self.results),
                    self.successful_extractions,
                    f"{(self.successful_extractions / len(self.results) * 100):.1f}%" if self.results else "0%",
                    'Selenium',
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                ]
            }
            stats_df = pd.DataFrame(stats_data)
            
            # Guardar en Excel
            with pd.ExcelWriter(self.excel_filename, engine='openpyxl') as writer:
                df_final.to_excel(writer, sheet_name='Sheet1', index=False)
                stats_df.to_excel(writer, sheet_name='Estad√≠sticas', index=False)
                
                # Ajustar ancho de columnas
                for sheet_name in writer.sheets:
                    worksheet = writer.sheets[sheet_name]
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 3, 60)
                        worksheet.column_dimensions[column_letter].width = adjusted_width
            
            logging.info(f"üìä Archivo actualizado: {self.excel_filename}")
            return self.excel_filename
            
        except Exception as e:
            logging.error(f"‚ùå Error actualizando Excel: {e}")
            return None
    
    def print_results(self):
        """Muestra los resultados en consola"""
        print("\n" + "="*100)
        print("üèÜ RESULTADOS DEL SCRAPING CON SELENIUM - 22 EQUIPOS")
        print("="*100)
        
        for i, result in enumerate(self.results, 1):
            print(f"\n{i}. üîç EQUIPO: {result['equipo_buscado']}")
            print(f"   ‚ö° Pr√≥ximo Rival: {result['Pr√≥ximo Rival']}")
            print(f"   üìÖ Pr√≥ximo Partido: {result['Pr√≥ximo Partido']}")
            print(f"   üèÜ Competici√≥n: {result['competicion']}")
            print("-" * 100)
    
    def print_statistics(self):
        """Muestra estad√≠sticas del scraping"""
        total = len(self.results)
        
        print(f"\nüìä ESTAD√çSTICAS DEL SCRAPING")
        print("="*50)
        print(f"üìà URLs procesadas: {total}")
        print(f"‚úÖ Extracciones exitosas: {self.successful_extractions}")
        print(f"üìä Tasa de √©xito: {(self.successful_extractions/total*100):.1f}%")
        print(f"üîß M√©todo utilizado: Selenium √∫nicamente")
        print(f"üìÅ Archivo Excel: {self.excel_filename}")
        print(f"‚è∞ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def close(self):
        """Cierra el driver de Selenium"""
        if self.driver:
            self.driver.quit()
            logging.info("üîß Driver de Selenium cerrado")

def main():
    """Funci√≥n principal"""
    # URLs completas para los 22 equipos
    urls = [
        # URLs existentes (3)
        "https://www.google.com/search?q=chacarita+proximo+partido&sca_esv=78cfef7a28cb5e8a&rlz=1C1GCEU_esAR965AR965&sxsrf=AE3TifPJr_kfVEaB4TZZ9yExTc9dGQEwaA%3A1754493858429&ei=onOTaOf7GZfY1sQPgaCh-QE&oq=chacarota+proximo+partido&gs_lp=Egxnd3Mtd2l6LXNlcnAiGWNoYWNhcm90YSBwcm94aW1vIHBhcnRpZG8qAggAMgcQIxiwAhgnMggQABgIGA0YHjIIEAAYgAQYogQyCBAAGIAEGKIEMggQABiABBiiBEjDDlAAWLsIcAB4AZABAJgBe6AB6waqAQM2LjO4AQPIAQD4AQGYAgegAu8FwgIGEAAYBxgewgIFEAAYgATCAggQABgHGAgYHsICCBAAGAUYBxgemAMAkgcDMi41oAeJNbIHAzIuNbgH7wXCBwUyLTEuNsgHSg&sclient=gws-wiz-serp",
        "https://www.google.com/search?q=tigre+proximo+partido&sca_esv=78cfef7a28cb5e8a&rlz=1C1GCEU_esAR965AR965&sxsrf=AE3TifPNgYOHeMHP_a6tgBK0orEmiocH2A%3A1754494095394&ei=j3STaKnoF5HJ1sQPlKOfgAo&ved=0ahUKEwjp68Pqv_aOAxWRpJUCHZTRB6AQ4dUDCBA&uact=5&oq=tigre+proximo+partido&gs_lp=Egxnd3Mtd2l6LXNlcnAiFXRpZ3JlIHByb3hpbW8gcGFydGlkbzIGEAAYBxgeMgYQABgHGB4yBhAAGAcYHjIGEAAYBxgeMgYQABgHGB4yBhAAGAcYHjIGEAAYBxgeMgYQABgHGB4yBhAAGAcYHjIGEAAYBxgeSMujAVDafljsnwFwCHgBkAEAmAHjAaAB5AqqAQYxMi4xLjG4AQPIAQD4AQGYAhSgAocKwgIKEAAYsAMY1gQYR8ICCBAAGAUYBxgewgIIEAAYBxgIGB7CAgYQABgFGB7CAgcQIxiwAhgnwgIIEAAYgAQYogTCAgoQIxiABBgnGIoFwgIGEAAYCBgemAMAiAYBkAYIkgcEMTguMqAH8F-yBwQxMC4yuAewCcIHBjItNS4xNcgHzQE&sclient=gws-wiz-serp",
        "https://www.google.com/search?q=platense+proximo+partido&sca_esv=78cfef7a28cb5e8a&rlz=1C1GCEU_esAR965AR965&sxsrf=AE3TifPdJaZ7_0X3_Snv5c_vKyp4vUOcOw%3A1754494130644&ei=snSTaIiJJ5Kq1sQP_uCAUA&oq=platense+proximo+partido&gs_lp=Egxnd3Mtd2l6LXNlcnAiGHBsYXRlbnNlIHByb3hpbW8gcGFydGlkbyoCCAAyChAjGIAEGCcYigUyCBAAGAUYBxgeMggQABgFGAcYHjIGEAAYCBgeMgYQABgIGB4yBhAAGAgYHjIGEAAYCBgeMggQABiABBiiBDIIEAAYgAQYogRIlnNQql5YiGtwAXgCkAEAmAGcAaABrweqAQM1LjS4AQHIAQD4AQGYAgmgAukGwgIEEAAYR8ICBhAAGAcYHsICBhAAGAUYHsICBxAjGLACGCfCAggQABgHGAgYHpgDAIgGAZAGCJIHAzQuNaAH20SyBwMyLjW4B8MGwgcHMi0xLjcuMcgHXQ&sclient=gws-wiz-serp",
        "https://www.google.com/search?q=arsenal+de+sarandi+proximo+partido",
        "https://www.google.com/search?q=union+magdalena+proximo+partido",
        "https://www.google.com/search?q=gimnasia+mendoza+proximo+partido",
        "https://www.google.com/search?q=puebla+proximo+partido",
        "https://www.google.com/search?q=los+andes+proximo+partido",
        "https://www.google.com/search?q=volos+proximo+partido",
        "https://www.google.com/search?q=boston+river+proximo+partido",
        "https://www.google.com/search?q=maldonado+proximo+partido",
        "https://www.google.com/search?q=circulo+deportivo+proximo+partido",
        "https://www.google.com/search?q=nueva+chicago+proximo+partido",
        "https://www.google.com/search?q=real+pilar+proximo+partido",
        "https://www.google.com/search?q=tristan+suarez+proximo+partido",
        "https://www.google.com/search?q=barracas+central+proximo+partido",
        "https://www.google.com/search?q=barcelona+guayaquil+proximo+partido",
        "https://www.google.com/search?q=dock+sud+proximo+partido",
        "https://www.google.com/search?q=atletico+tucuman+proximo+partido",
        "https://www.google.com/search?q=liverpool+montevideo+proximo+partido",
        "https://www.google.com/search?q=rosario+central+proximo+partido",
        "https://www.google.com/search?q=san+martin+san+juan+proximo+partido"
    ]
    
    print("üöÄ SCRAPER DE F√öTBOL - 22 EQUIPOS COMPLETOS")
    print("="*60)
    print("üë§ Usuario: Independiente7L")
    print(f"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("üîß M√©todo: Selenium √∫nicamente")
    print("üìÅ Archivo: proximos_partidos.xlsx")
    print(f"‚öΩ Equipos: 22 equipos completos")
    print("="*60)
    
    # Crear el scraper
    scraper = FootballScraperSelenium()
    
    try:
        # Procesar URLs
        results = scraper.scrape_multiple_urls(urls)
        
        # Mostrar resultados
        scraper.print_results()
        scraper.print_statistics()
        
        # Actualizar Excel
        filename = scraper.update_excel()
        if filename:
            print(f"\n‚úÖ Archivo Excel actualizado: {filename}")
        else:
            print("\n‚ùå Error actualizando el archivo Excel")
        
    finally:
        # Cerrar recursos
        scraper.close()

if __name__ == "__main__":
    main()
